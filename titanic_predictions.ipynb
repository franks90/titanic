{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is a simple template notebook in order to achieve 80% of accuracy in the Kaggle Titanic Competion, without a particular attention on modelling. The purpose is to show how with a good EDA it is possible to improve dramatically the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import libreries\n",
    "\n",
    "We import the needed libriries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surname and Title split\n",
    "\n",
    "We start with splitting the Name column into Surname and Title columns. We do it in order to take into account the incidence of these two fields for the passengers' survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataset = pd.read_csv('train.csv')\n",
    "titanic_test_set = pd.read_csv('test.csv')\n",
    "titanic_dataset['Surname']=titanic_dataset.Name.str.split(',',expand=True)[0]\n",
    "titanic_test_set['Surname']=titanic_test_set.Name.str.split(',',expand=True)[0]\n",
    "titanic_dataset['Title']=titanic_dataset.Name.str.split(',',expand=True)[1].str.split('.',expand=True)[0]\n",
    "titanic_test_set['Title']=titanic_test_set.Name.str.split(',',expand=True)[1].str.split('.',expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Braund</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked    Surname  Title  \n",
       "0      0         A/5 21171   7.2500   NaN        S     Braund     Mr  \n",
       "1      0          PC 17599  71.2833   C85        C    Cumings    Mrs  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Heikkinen   Miss  \n",
       "3      0            113803  53.1000  C123        S   Futrelle    Mrs  \n",
       "4      0            373450   8.0500   NaN        S      Allen     Mr  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the Family number column as the total number of people with the same Surname, including also Homonyms. We use both training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_sur={}\n",
    "for name, group in titanic_test_set.append(titanic_dataset,sort=False).groupby('Surname'):\n",
    "    lbl_sur[name]=len(group)\n",
    "titanic_dataset['FamilyNumber']=titanic_dataset.Surname.map(lbl_sur)\n",
    "titanic_test_set['FamilyNumber']=titanic_test_set.Surname.map(lbl_sur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the isAlone column as the representation of the pepole which are not part of a family. The HasHomonym column is quiet straightforward to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dataset['isAlone'] = titanic_dataset.SibSp+titanic_dataset.Parch==0\n",
    "titanic_test_set['isAlone'] = titanic_test_set.SibSp+titanic_test_set.Parch==0\n",
    "hasHo=[]\n",
    "for i in range(len(titanic_dataset)):\n",
    "    if titanic_dataset.iloc[i]['isAlone'] and titanic_dataset.iloc[i]['FamilyNumber'] > 1:\n",
    "        hasHo.append(True)\n",
    "    else:\n",
    "        hasHo.append(False)\n",
    "titanic_dataset['HasHomonym']=hasHo\n",
    "\n",
    "hasHo=[]\n",
    "for i in range(len(titanic_test_set)):\n",
    "    if titanic_test_set.iloc[i]['isAlone'] and titanic_test_set.iloc[i]['FamilyNumber'] > 1:\n",
    "        hasHo.append(True)\n",
    "    else:\n",
    "        hasHo.append(False)\n",
    "titanic_test_set['HasHomonym']=hasHo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling and Mean Encoding\n",
    "\n",
    "We now use both training and test sets to calculate labels for Cabin and Surname columns, together with passageners' mean age. Finally we fill the Nan values with the age mean for the Age column, and with -1 for the Surname and Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Labelling and filling NaN ###\n",
    "\n",
    "mean_age=titanic_test_set.append(titanic_dataset, sort=False).Age.mean()\n",
    "lbl_cabin = {k: v for v, k in enumerate(\n",
    "    titanic_test_set.append(titanic_dataset, sort=False)['Cabin'].unique())}\n",
    "lbl_Surname = {k: v for v, k in enumerate(\n",
    "    titanic_test_set.append(titanic_dataset, sort=False)['Surname'].unique())}\n",
    "\n",
    "titanic_dataset.Age = titanic_dataset.Age.fillna(mean_age)\n",
    "titanic_dataset.Cabin = titanic_dataset.Cabin.map(lbl_cabin)\n",
    "titanic_dataset.Surname = titanic_dataset.Surname.map(lbl_Surname)\n",
    "titanic_dataset=titanic_dataset.fillna(-1)\n",
    "\n",
    "titanic_test_set.Age = titanic_test_set.Age.fillna(mean_age)\n",
    "titanic_test_set.Cabin = titanic_test_set.Cabin.map(lbl_cabin)\n",
    "titanic_test_set.Surname = titanic_test_set.Surname.map(lbl_Surname)\n",
    "titanic_test_set=titanic_test_set.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important part. We label four fields (Sex, Embarked, Pclass and Title) using the Mean Encoding technique. We choose a Kfold validation strategy in order to avoid overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f.guarino\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "###### MEAN ENCODING ######\n",
    "\n",
    "skf = StratifiedKFold(5,shuffle=True,random_state=123).split(titanic_dataset.values,\n",
    "                                                             titanic_dataset['Survived'].values)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "for tr_ind, val_ind in skf:\n",
    "    X_tr, X_val = titanic_dataset.iloc[tr_ind], titanic_dataset.iloc[val_ind] \n",
    "    for col in ['Sex','Embarked','Pclass','Title']:\n",
    "        means = X_val[col].map(X_tr.groupby(col)['Survived'].mean())\n",
    "        X_val[col+'_mean_target']=means\n",
    "    new_df = new_df.append(X_val)\n",
    "\n",
    "emb_dict = new_df.groupby('Embarked')['Embarked_mean_target'].mean().to_dict()\n",
    "sex_dict = new_df.groupby('Sex')['Sex_mean_target'].mean().to_dict()\n",
    "pclass_dict = new_df.groupby('Pclass')['Pclass_mean_target'].mean().to_dict()\n",
    "title_dict = new_df.groupby('Title')['Title_mean_target'].mean().to_dict()\n",
    "\n",
    "titanic_dataset['Embarked_mean_target'] = titanic_dataset.Embarked.map(emb_dict)\n",
    "titanic_dataset['Sex_mean_target'] = titanic_dataset.Sex.map(sex_dict)\n",
    "titanic_dataset['Pclass_mean_target'] = titanic_dataset.Pclass.map(pclass_dict)\n",
    "titanic_dataset['Title_mean_target'] = titanic_dataset.Title.map(title_dict)\n",
    "titanic_test_set['Embarked_mean_target'] = titanic_test_set.Embarked.map(emb_dict)\n",
    "titanic_test_set['Sex_mean_target'] = titanic_test_set.Sex.map(sex_dict)\n",
    "titanic_test_set['Pclass_mean_target'] = titanic_test_set.Pclass.map(pclass_dict)\n",
    "titanic_test_set['Title_mean_target'] = titanic_test_set.Title.map(title_dict)\n",
    "\n",
    "titanic_dataset=titanic_dataset.fillna(-1)\n",
    "titanic_test_set=titanic_test_set.fillna(-1)\n",
    "titanic_dataset.isAlone = titanic_dataset.isAlone.astype(float)\n",
    "titanic_dataset.HasHomonym = titanic_dataset.HasHomonym.astype(float)\n",
    "titanic_test_set.isAlone = titanic_test_set.isAlone.astype(float)\n",
    "titanic_test_set.HasHomonym = titanic_test_set.HasHomonym.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Modelling\n",
    "\n",
    "Now that the dataset is ready, we can build a simple model. First, we scale the data using both training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcol=['Age','SibSp','Parch','Cabin','Fare','Surname','FamilyNumber','isAlone','HasHomonym',\n",
    "      'Pclass_mean_target','Sex_mean_target','Embarked_mean_target','Title_mean_target']\n",
    "\n",
    "y_col = ['Survived']\n",
    "\n",
    "X_train = titanic_dataset[fcol].values\n",
    "X_test = titanic_test_set[fcol].values\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(np.concatenate([X_train,X_test]))\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using a Stratified K-fold strategy for cross validation, we train a Random Forest model, trying different hyperparameters. As we can see, the model is a little overfitted. I invite you to improve the model in order to achieve a better generalization on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean tr accuracy is  0.9520202259639061\n",
      "The mean val accuracy is  0.8305296818518562\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(5,shuffle=True,random_state=123).split(X_train,\n",
    "                                                             titanic_dataset['Survived'].values)\n",
    "y_tr = titanic_dataset[y_col].values\n",
    "y_tr = y_tr.reshape(len(y_tr),)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200,max_depth=40,max_features=10,\n",
    "                             min_samples_leaf=2,random_state=123,n_jobs=-1)\n",
    "#clf = LogisticRegression(C=9)\n",
    "\n",
    "accuracy_tr = []\n",
    "accuracy_val = []\n",
    "\n",
    "for tr_ind, val_ind in skf:\n",
    "    X_tr, X_val = X_train_scaled[tr_ind], X_train_scaled[val_ind]\n",
    "    clf.fit(X_tr,y_tr[tr_ind])\n",
    "    accuracy_tr.append(clf.score(X_tr,y_tr[tr_ind]))\n",
    "    accuracy_val.append(clf.score(X_val,y_tr[val_ind]))\n",
    "\n",
    "print('The mean tr accuracy is ', np.mean(accuracy_tr))\n",
    "print('The mean val accuracy is ', np.mean(accuracy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the validation is done, we can fit the model over the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200,max_depth=40,max_features=10,\n",
    "                             min_samples_leaf=2,random_state=123,n_jobs=-1)\n",
    "clf.fit(X_train_scaled,titanic_dataset['Survived'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just prepare the submission.csv file to submit to the competition. You should roughly achive a score of 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test_scaled)\n",
    "\n",
    "with open('submission.csv','w') as f:\n",
    "    f.write('PassengerId,Survived\\n')\n",
    "    for i in range(len(titanic_test_set)):\n",
    "        f.write('{}'.format(titanic_test_set.iloc[i]['PassengerId'])+','+\n",
    "                   '{}'.format(y_test[i])+'\\n')\n",
    "                    #'{}'.format('0')+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
